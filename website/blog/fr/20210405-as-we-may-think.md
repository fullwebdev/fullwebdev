# Vannevar Bush et la naissance des NTIC

::: tip
Infos complémentaires pour la chronique "Les anecdotes historiques" présentée durant [Les briques du Web S01E02](https://youtu.be/rI6xUkOnyB0?t=2621) le 30 mars 2021.
:::

::: warning
**sexisme & informatique**

J'ai, dans cette chronique, utilisé le passage suivant comme prétexte pour évoquer la question du sexisme dans l'informatique : _« De telles machines auront un appétit énorme. L’une d’entre elles recevra les instructions et les données d’une pièce **remplie de demoiselles** armées de claviers perforateurs \[...\]. »_

Cette parenthèse m'a surtout été inspirée par le podcast _Les couilles sur la table_, en particulier l'épisode 58, « [Des ordis, des souris et des hommes](https://www.binge.audio/podcast/les-couilles-sur-la-table/des-ordis-des-souris-et-des-hommes) », que je vous recommande vivement d'écouter.

Et puis tant qu'à faire, profitez-en pour écouter les autres épisodes !
:::

## C'est quoi au juste, "l'Histoire" ?

> « Là où un mensonge est bon à dire, n'hésitons pas à le dire. » - citation [attribuée](https://citations.ouest-france.fr/citation-herodote/la-ou-mensonge-bon-dire-120673.html) à Hérodote, dit le "Père de l’Histoire"

L'**_Histoire_**, avec un grand H, est tout d'abord une science, étudiant le passé de l'humanité.
Pour reconstruire les faits, les historiens et historiennes ont besoin de récits, autrement dit, d'**_histoires_** (avec un petit h).
Ces différents "bouts d'Histoire" sont forcément partiels et biaisés.
Retracer le déroulement réel des évènements demande donc de collecter un grand nombre de sources.
Sources qui doivent être ensuite recoupées et comparées.

Il s'agit d'un travail fastidieux.
Ou, pour le dire autrement : beaucoup trop chiant... à moins d'être passionné.

Et ça tombe bien : je suis un de ces passionnés.
Passer une semaine entière à lire de vieux emails et commentaires de code est pour moi l'équivalent d'une finale de coupe du monde (vu qu'apparemment, les gens normaux s'intéressent à ce genre de frivolités).
Mais ma passion a ses limites.
Contrairement à un véritable historien, je me lasserais vite si ces recherches devaient se faire dans une bibliothèque, en suivant des horaires contraignants, ou sur le terrain, en fouillant la poussière.
Le Web me permet d'effectuer mes "fouilles" d'où je veux, quand je veux.
C'est un medium idéal pour effectuer des recherches en amateur.

Le medium (c'est-à-dire le moyen utilisé pour transmettre une information) est un élément clé dans tous les domaines.
Chaque medium impose ses propres contraintes.

Disons, [au hasard](https://twitter.com/LesBriquesDuWeb), que vous souhaitiez parler d'Histoire toutes les deux semaines sur un super podcast diffusé via [Twitch](https://www.twitch.tv/rdvspeakers), [Youtube](https://www.youtube.com/channel/UCnwt2UOOdU83KurAPuLcy6g), [Spotify](https://open.spotify.com/show/2OKbLLelv3Q2hVZsQnBW2u?si=mK_5aCCeST-N1v7WiWXg0g), et toutes les meilleures plateformes de diffusion audio.
Donner plein de détails, en listant des évènements et les sources utilisées, est inutile : tout le monde s'ennuierait à mourir au bout de quelques secondes.
Vous devez "_raconter une **histoire**_", autrement dit, faire du "_storytelling_" (oui, ça veut dire exactement la même chose, mais c'est plus _hype_ en anglais).
Ce qui est très éloigné de l'Histoire à proprement parler.
Car il vous faut prendre des raccourcis, et, souvent, exagérer l'importance d'un évènement (disons, la publication d'un article) ou d'une personne (au pif, Vannevar Bush), et accentuer des aspects divertissants ("Vannevar Bush se trompait, lol").
D'une certaine manière, vous allez mentir par omission ou exagération.
Vous "_racontez des **histoires**_".

Enfin, l'**_Histoire_** peut également désigner une période séparée de la préhistoire, par l'invention de l'écriture aux alentours de 3500 av. JC.
Sans documents écrits, l'étude de la préhistoire doit se faire à l'aide d'indices matériels.
Encore une fois, le medium fait toute la différence.
Sans écrit, la préhistoire est plus difficile à étudier que l'Histoire.

L'informatique elle-même a son "Histoire" et sa "préhistoire".
Deux périodes distinctes, qui doivent être abordées différemment.

## Quand commence l'Histoire de l'informatique ?

L'Histoire qui m'intéresse le plus commence avec l'apparition d'Internet et des premières communautés en ligne ;
des emails, forums et canaux IRC ;
des vieux dépôts SVN et Git ;
des premiers blogs et sites web ;
en bref : des traces écrites, dans lesquelles je peux "fouiller" à loisir.
Donc, dans les années 90, avec la naissance du Web.
Ça tombe bien, je suis né peu de temps avant ça.

Mais je dois bien reconnaitre que 30 ans ne suffisent pas à faire "l'Histoire".
Il faut remonter un peu plus loin pour avoir une vision d'ensemble de l'Histoire de l'informatique.
Des périodes pour lesquels je dois faire appel à de vrais historiens.

Au IIIème millénaire avant JC (donc au tout début de l'Histoire elle-même, si vous suivez bien), des calculs algorithmiques avaient déjà été retranscrits par les babyloniens [sur des tablettes cunéiformes](http://images.math.cnrs.fr/Mathematiques-en-Mesopotamie)...

Bon, je vous l'accorde, remonter aussi loin n'est pas très utile.
Mieux vaut s'en tenir à des choses plus récentes, histoire de ne pas brasser trop large.
Utilisons le matériel (donc, les ordinateurs), comme fil conducteur.

La Pascaline ("première" machine à calculer, créée vers 1645), les métiers à tisser Bouchon (1725-1728) et les cartes perforées Jacquard (1801), l'Arithmomètre (1820), la "machine à différence" de Charles Babbage (pour laquelle Ada Lovelace écrit le "premier programme", en 1843), l'analyseur différentiel de James Thomson (1876)...
Toutes ces machines sont incomplètes.
Aucune n'est donc un véritable ordinateur.
Mais elles ont toutes, à leur manière, participé à la naissance de l'informatique.
Elles appartiennent à sa "préhistoire".

Il faut une idée nouvelle pour ouvrir l'Histoire.
Idée qui apparait en 1936, dans l'article d'Alan Turing _« On Computable Numbers, with an Application to the Entscheidungsproblem"_.
La _machine de Turing_ énonce enfin clairement ce que devrait être un ordinateur.
Mais ce n'est, encore, qu'un modèle abstrait.

Créer un véritable ordinateur demande des moyens considérables.
Seule l'armée, en période de guerre, dispose (malheureusement) de tels moyens.

## Détruire des mondes, et en créer de nouveaux

> « _Maintenant, je suis devenu la mort, le destructeur des mondes._ » - Extrait de la Bhagavad-Gita [cité par Robert Oppenheimer](https://www.wired.co.uk/article/manhattan-project-robert-oppenheimer) suite à la création de la bombe atomique.

L'horreur de la seconde guerre mondiale dépasse largement notre imagination.
Aucune histoire, aucun document, ne permet vraiment d'en saisir l'étendue.
Nazisme, Fascisme, Blitzkrieg, Shoa, Porajmos...
La liste des atrocités commises en Europe est beaucoup trop longue.

Quoi que puissent en dire certains négationnistes, révisionnistes, et autres hypocrites nostalgiques du bruit des bottes, celles-ci n'ont absolument jamais, même indirectement, donné naissance à quoi que ce soit de "bon".
Une guerre n'est pas la "source" des évènements qui lui succèdent.
Chaque moment de l'Histoire est le résultat d'un nombre considérable d'influences.
Dire, arbitrairement, qu'un "progrès" est le résultat d'une influence unique, serait un non-sens.

La seconde guerre mondiale est intimement liée au totalitarisme.
Car une guerre totale implique des régimes (ou du moins des pratiques) totalitaires.
Dans cette logique, toute la société doit se consacrer à un objectif unique : éradiquer "l'ennemie".
Or, le totalitarisme "permet" donc de mobiliser des moyens considérables.
Moyens qui, parfois, "accélèrent" l'Histoire.

Le totalitarisme est nécessairement manichéen.
_« Ou vous êtes avec nous, ou vous êtes contre nous »_.
Tout scientifique doit alors choisir entre la collaboration, permettant de poursuivre ses travaux, la fuite, ou la résistance.

Konrad Zuse, ingénieur allemand, créé "dans son coin" un premier ordinateur mécanique (Zuse 1, ou Z1) entre 1935 et 1938.
Plutôt que la fuite ou la résistance, il accepte de conclure un [« pacte avec le diable »](https://link.springer.com/content/pdf/bfm%3A978-3-662-02931-2%2F1.pdf) lorsqu'il est appelé sous les drapeaux, en 1939.
Pouvant ainsi poursuivre ses travaux, il créé le Z2 en 1940, puis le Z3 en 1941, au bénéfice de "l'effort de guerre" Nazi.
Le Zuse 3 est alors le tout premier calculateur programmable automatique (ou "ordinateur") au monde.

Des travaux similaires furent entrepris outre-atlantique à la même période.
Le Harvard Mark I, créé par IBM et livré à Harvard en 1944, fut le "premier ordinateur américain".
Largement financé par l'armée américaine, il joue alors un rôle important dans l'US Navy.
Il est même utilisé par John von Neumann dans le cadre du projet Manhattan, qui donnera naissance à la bombe atomique.

Les 6 et 9 août 1945, Hiroshima et Nagazaki sont souflés par l'arme nucléaire.
Cet évènement sans précédent impact durablement les consciences.
Soudain, l'être humain détient le pouvoir de détruire le monde.

La guerre froide succède à la seconde guerre mondiale.
Le bloc de l'ouest nourri alors une peur obsessionnelle de l'holocauste nucléaire et des communistes.
L'État américain glisse à son tour vers le totalitarisme et la surveillance globale.
La doctrine Truman et le Markartisme donnent une place toujours plus grande à l'armée et aux services de renseignement.
Une vision du monde mécanique, viriliste et bureaucratique se met en place.
Un "discours du monde clos" semble guider l'Histoire de l'informatique, largement financée et mobilisée par l'armée américaine.

Pour autant, les États-Unis se sombrent pas totalement dans le totalitarisme.
D'autres discours, d'autres mondes, peuvent se développer à la marge.

## Une histoire aux multiples facettes

Le rôle prépondérant du DoD (département de la défense américaine), dans les années 40 à 70, est plutôt évident.
Chaque étape, chaque innovation, porte la marque de cette organisation, ou d'une de ses branches, comme le DARPA.
Il est alors facile de ne se focaliser que sur cet aspect de l'Histoire.
De glorifier le rôle de l'armée et de la guerre.
De s'exalter devant la puissance de "grands hommes" s'épanouissant dans un "choc civilisationnel".

Mais les ordinateurs et réseaux sont bien plus que de simples "outils".
Les communications qu'ils permettent d'établir, les calculs qu'ils permettent de réaliser, sont un reflet de notre société.
Ils ne sont qu'un des rouages d'une évolution continue et complexe.
Pourquoi parlerait-on, sinon, de _Nouvelles_ technologies de l'information et de la communication ?

La transmission d'informations a déjà franchis un cap important en 1794, avec la création du premier télégraphe.
En 1813, Claude Henri de Saint-Simon fonde une philosophie des réseaux qui inspire le passage à l'ère industrielle et la construction des chemins de fer.
On passe alors de la "gouvernance des hommes" à "l'administration des choses".
La société dans son ensemble n'est plus vue comme une masse à diriger, mais comme un système complexe autonome, avec sa propre "biologie".
Un nouvel ensemble de disciplines, les _sciences sociales_, nait pour étudier la société, et donc notamment les interactions entre individus.

Pendant un temps, l'ingénie semble évoluer de son côté, sans se soucier de telles considérations "philosophiques".
Ralph Hartley (1927), Alan Turing (1936) et enfin John Von Neumman, étant avant tout des ingénieurs, ont surtout étudié l'information comme un signal physique et mécanique.
Beaucoup de leurs idées sont pourtant dans la continuité des penseurs de l'ère industrielle, et en particulier de Saint-Simon.

Claude Shannon, un autre ingénieur et mathématicien américain ayant travaillé avec les services secrets, définie une théorie mathématique de la communication en 1948.
Froide et mécanique, cette théorie aborde encore la technologie comme un simple instrument.
Shannon fut pourtant largement influencé par un autre mathématicien, Norbert Wiener, qui publie la même année _Cybernetics, or Control and Communication in the Animal and the Machine_ ("_La cybernétique. Information et régulation dans le vivant et la machine_").
Faisant le lien avec les sciences sociales, Wiener considère l'information comme un élément clé de la société.
Il imagine alors un nouvel idéal, la « société de l'information », qui ne pourra exister que si l'information est libre de circuler.
Une utopie qui est donc inconciliable avec la pratique du secret et la marchandisation de l'information.

Via ces deux ouvrages, Shannon et Wiener fondent les sciences de l'information et de la communication, qui guideront continuellement l'Histoire de l'informatique.
Les sciences sociales, mais aussi la contre-culture américaine, et en particulier le Free Speech Mouvement, s'empareront largement de ces sujets.
Nous leur devons en grande partie notre société de l'information actuelle, ainsi que les outils qui peuvent nous permettre de combattre ses dérives.

## Rôle de Vannevar Bush

Mais revenons au sujet principal de cette chronique.

Dans les années 20 et 30, Vannevar Bush est un des plus grands spécialistes de la proto-informatique.
Après obtention d'un double doctorat en ingénierie du MIT et de Harvard, il rejoint le département d'électrotechnique du MIT, dont il restera membre jusqu'en 1944.

Pour comprendre ses premiers travaux, nous devons déjà définir ce qu'est un ordinateur.
Disons, pour simplifier, qu'un ordinateur est un calculateur numérique.
Un calculateur numérique effectue des calculs de manière séquentielle, en manipulant des données numériques discrètes.
Dans les années 30, ce type de système reste à inventer.

Un autre type de calculateur, dit analogique, existe cependant depuis la fin du XIXᵉ siècle.
Dans un calculateur analogique, les données sont représentées par des variations de quantités physiques, telles que le voltage.
Les calculs y sont donc effectués en parallèle, sur des variables continuent.
Le tout étant modélisé par un ensemble de modules électriques ou électro-mécaniques, généralement connectés via un tableau de câblage.
Les calculateurs analogiques sont donc des outils extrêmement spécialisés.
Ils ne sont pas, à proprement parler, des "ordinateurs".
Leur conception constitue cependant une étape importante dans l'Histoire des ordinateurs.

Vannevar Bush est un des premiers ingénieur à travailler à la conception de calculateurs analogiques pouvant effectuer des calculs complexes.
De 1927 à 1931, il conçoit ainsi un "analyseur" capable de résoudre plusieurs types de calculs différentiels complexes.

![Analyseur Différentiel de Cambridge, 1938](/illustrations/images/history/Cambridge_differential_analyser.jpg)

Wiener ayant lui-même rejoint le MIT en 1919 en tant que mathématicien, travaille étroitement avec Bush durant toutes ces années.
Ce type de collaboration entre différents domaines scientifiques est une des principales sources des modèles cybernétiques que Wiener formalisera 30 ans plus tard.

Pour autant, Bush est un homme de "sciences dures" qui considère que les sciences sociales n'ont qu'un intérêt très limité.

> Pour citer [sa biographie](https://mitpress.mit.edu/books/endless-frontier) : « J'ai de sérieuses réserves quant à ces études où quelqu'un sort, interviewe un groupe de personnes et lit beaucoup de choses, pour finalement écrire un livre \[...\] que personne ne lira jamais. »

Outre ces recherches, sa carrière est surtout dictée par la première, puis la seconde guerre mondiale.
Les États-Unis entretiennent alors un lien étroit entre pouvoirs militaires, entreprises industrielles et recherche universitaires.
Vannevar Bush exprime très tôt son inquiétude face à l'influence du gouvernement sur les projets de recherche, sans pour autant s'interdire d'y contribuer.

De 1916 à 1919, Bush débute sa carrière à l'AMRAD (American Radio and Research Corporation) et au NRC (National Research Council).
Ses premiers travaux sont naturellement tournés vers des objectifs militaires tels que la détection de sous-marins.

En 1938, Bush est nommé président du CIW (Carnegie Institution of Washington).
Il réduit alors considérablement les fonds de l'_Eugenics Record Office_ (renommé par la même occasion _Genetics Record Office_) et pousse son directeur, Harry H. Laughlin, à la retraire.

> Laughlin fut un des eugénistes les plus influents de son temps.
> Il mena notamment des recherches sur "l'héritage génétique" des sénateurs américains et eût un rôle important dans la promulgation de lois de stérilisation obligatoire des membres "inaptes" (_"unfit"_) de la population.
> Ces lois influencèrent fortement la politique eugéniste Nazi, ce qui vaudra à Laughlin d'être nommé professeur honoraire de l'université de Heidelberg en 1936.

Bush dispose, en tant que président du CIW, d'un pouvoir d'influence important sur le gouvernement américain.
Ce qui lui permet, en 1940, de persuader Roosevelt d'améliorer la coopération entre recherche scientifique et militaire en créant le NDRC (_National Defense Research Committee_).
Bush est, naturellement, nommé directeur de ce commité, puis de l'OSRD (_Office of Scientific Research and Development_).
Il joue alors un rôle crucial dans la recherche militaire durant la seconde guerre mondiale.

En 1940, il refuse à Wiener l'attribution de fonts pour la construction d'un calculateur numérique, qu'il estime moins prometteur que les calculateurs analogiques.
Le projet Manhattan sera également initié sous son influence.
Il recommandera par la suite de larguer la bombe atomique sur une « cible industrielle » japonaise, sans avertissement et le plus rapidement possible.

Vannevar Bush était à la fois un "homme de son temps", et un "homme d'exception".
Une personnalité aux multiples aspects, ayant mené de nombreuses actions d'envergures dans un contexte complexe.
Il a fortement contribué à accroitre le pouvoir de l'armée et du gouvernement américain sur la recherche, tout en espérant que celui-ci se résorbe au sortir de la guerre.
Finalement, il a même, rétrospectivement, fortement pesé dans l'avènement de la société de l'information, tout en en rejetant de nombreux aspects.

## « As We May Think »

C'est finalement son article « As We May Think », publié dans _The Atlantic_ en juillet 1945, que l'Histoire retiendra le mieux.

:::warning
Toutes les citations suivantes sont issues de la traduction de cet article en français ([« Comme nous pourrions penser »](http://www.softphd.com/these/traduction/vannevar-bush-as-we-may-think)) par Anthony Masure pour sa thèse [_Le design des programmes - Des façons de faire du numérique_](http://www.softphd.com/).
:::

Vannevar Bush constate tout d'abord les limites du traitement de l'information :

> « Nos méthodes de transmission et de vérification des résultats de recherche sont datées et désormais inadaptées à leur objet. \[...\] La difficulté semble moins provenir du fait que nous publions sans recul vu l’étendue et la variété des sujets actuels, mais plutôt du fait que le rythme de publication a augmenté bien au-delà de nos capacités actuelles d’enregistrement. \[...\] On observe pourtant les signes d’un changement grâce à l’émergence de nouveaux appareils. \[...\] Un enregistrement, s’il doit être utile à la science, doit pouvoir être prolongé. Il doit certes être stocké, mais avant tout il doit pouvoir être consulté. \[...\] Même s’il n’existe pas encore de nouvelles techniques d’enregistrement, les méthodes actuelles sont certainement en train de se modifier et d’évoluer. »

L'ensemble de l'article suit cette idée initiale, pour mieux la détailler, et anticiper les innovations futures.

De là, nous pouvons lire ce texte de deux manières très différentes.
Tout d'abord, en tant qu'ingénieur, ou du moins, en tant que passionné d'informatique vivant au XXIᵉ siècle.
Bush fait de nombreuses "prédictions" techniques détaillées, qu'il énonce avec beaucoup de certitude et d'emphase.

> « Voyons ce que ces découvertes vont _logiquement_ voire _inévitablement_ impliquer. L’appareil photographique du futur se porte sur le front, et a la forme d’une bosse à peine plus grande qu’une noix. \[...\] Ce n’est, après tout, qu’une extrapolation des pratiques actuelles. »

![Illustration originale de l'article dans _The Atlantic_, présentant cet "appareil photographique du futur"](/illustrations/images/third-party/The_Memex.png){width=500px}

Aujourd'hui, ces passages donnent plus envie de rire qu'autre chose, comme les illustrations du XXᵉ siècle d'Albert Robida.

![Un quartier embrouillé du vingtième siècle illustré par Albert Robida en 1893](/illustrations/images/history/robida_quartier-embrouille.jpg)

Là encore, le medium a certainement eu une grande influence sur le contenu.
Bush s'adresse ici au grand public, via un magazine culturel d'orientation littéraire.
Il doit donc vendre du rêve à une audience en manque d'avenir radieux.
Il doit s'appuyer sur sa propre autorité, alors même qu'il est apparu en couverture du Times moins d'un an plus tôt.
Il doit incarner "celui qui sait" face à ceux qui "veulent savoir".
On comprendra donc facilement qu'il puisse avoir "pété plus haut que son cul".

Il faut donc faire abstraction de cet aspect plutôt comique pour voir le véritable intérêt de cet article.

En particulier, un premier pas vers l'hypertexte :

> « Notre incapacité à accéder à \[une information\] est principalement causée par l’artificialité \[des\] systèmes \[actuels\] d’indexation. \[...\] Après avoir trouvé un élément, il faut sortir du système et y revenir en utilisant un chemin différent.
>
> L’esprit humain ne fonctionne pas de cette façon. Il opère par association. Avec un élément en tête, il passe immédiatement au suivant, par association d’idées, en accord avec un réseau d’intrications complexes générés par les cellules du cerveau. Il a bien sûr d’autres caractéristiques ; les chemins de pensées qui ne sont pas fréquemment utilisés sont voués à s’effacer, les informations ne sont jamais complètement permanentes, la mémoire est transitoire. Mais la rapidité, la complexité des chemins parcourus, les détails des images mentales, sont plus incroyablement inspirantes que n’importe quoi d’autre dans la nature.
>
> L’humain ne peut espérer réussir à dupliquer ses capacités mentales artificiellement, mais il est cependant capable d’en tirer des leçons. Il pourrait même s’améliorer, puisque ses enregistrements ne sont pas parfaitement fiables. Une des premières choses pouvant être retirée de cette analogie concerne encore une fois la sélection. La sélection par association, plutôt que par indexation, pourrait sans doute être mécanisée. »

Concept qu'il développe par la suite en imaginant, encore une fois, un appareil plutôt fantaisiste : le _Memex_.
Mais cette anticipation hasardeuse cache des idées extrêmement importantes :

> « \[...\] une indexation associative — l’idée d’avoir une disposition dans laquelle tout objet peut être convoqué à volonté pour sélectionner immédiatement et automatiquement un autre. \[...\] Le processus permettant de lier deux éléments est essentiel.
>
> \[...\] Lorsque de nombreux articles sont ainsi reliés pour former un itinéraire, ils peuvent être passés en revue \[...\]. C’est exactement comme si des éléments physiques d’origines diverses avaient été rassemblés pour former un livre. Cependant le memex est plus que cela, puisque n’importe quel élément peut appartenir à de nombreux itinéraires différents. »

Pour le coup, on pourrait même dire que Bush anticipe la création de Wikipédia :

> « Des formes inédites d’encyclopédies vont apparaître, prêtes à l’emploi grâce aux intersections des chemins d’associations de documents qui les traversent. »

Enfin, les dernières parties de l'article détaillent les usages possibles d'une telle technologie.

Là encore, l'informaticien retiendra surtout l'anticipation des interfaces neuronales :

> « Dans un autre monde, toutes les formes d’intelligence provenant du son ou de la vue ont été réduites à un courant variable dans un circuit électrique afin de pouvoir les transmettre. À l’intérieur du corps humain, le même type de processus se produit. Doit-on toujours les transformer en mouvements mécaniques pour passer d’un phénomène électrique à l’autre ? »

Mais ces passages permettent surtout de voir que cet article peut être lu, comme nous le disions plus tôt, d'une seconde manière.
Mises bout à bout, les idées énoncées en sous-texte dessinent une image plus large.
Car Vannevar développe également une pensée de la société de l'information.

> « Cela donne naissance à une nouvelle profession d’explorateurs et créateurs d’itinéraires, dont les représentants prennent plaisir à établir des itinéraires utiles dans l’énorme masse des enregistrements communs. L’héritage d’un maître n’est plus seulement ce qu’il apporte au savoir humain, c’est aussi l’ensemble des réseaux et itinéraires lui ayant servi à échafauder à sa pensée. »

« As We May Think » permet de mieux comprendre les transformations radicales des moyens de communication durant la fin des années quarante et les décennies qui suivirent.
Comment l'horreur de la guerre et de l'arme nucléaire fit naitre une envie de changer le monde.
De permettre, via de nouvelles technologies, sciences et pratiques, l'avènement d'une société où le partage de connaissance et l'échange entre personnes se fasse naturellement.

Nous vivons bien, quatre-vingts ans plus tard, dans cette société de l'information.
Nous sommes pourtant très loin de vivre dans une utopie de coopération et d'entente.

En 2021, la conclusion de Bush semble toujours d'actualité :

> « On peut supposer que l’esprit humain devrait être élevé pour pouvoir examiner son passé trouble et mieux analyser ses problèmes actuels. L’humain a construit une civilisation si complexe qu’il a besoin de mécaniser ses enregistrements s’il veut aller jusqu’à la conclusion logique de l’expérience sans s’enliser en chemin en surchargeant sa mémoire limitée. Ses excursions seront plus agréables s’il acquiert le privilège d’oublier les multiples éléments dont il n’a pas besoin dans l’immédiat, avec l’assurance de pouvoir les retrouver s’ils s’avèrent importants.
>
> Les applications de la science ont fourni à l’homme une maison bien équipée et elles lui apprennent à vivre sereinement. Elles lui ont permis de faire s’affronter des peuples avec des armes cruelles. Elles peuvent encore lui permettre de développer un savoir commun et de grandir dans la sagesse de l’expérience ainsi accumulée. L’humanité périra peut être dans un conflit avant d’apprendre à manier ce savoir pour le bien commun. Pourtant, dans l’application de la science aux besoins et aux désirs de l’homme, ce serait un bien mauvais moment pour interrompre ce processus, ou perdre espoir quant à son issue. »

## Ressources

- Vannevar Bush, « [As We May Think](https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/) », _The Atlantic_, juillet 1945
- Fred Turner, _[Aux sources de l'utopie numérique](https://cfeditions.com/utopieNumerique/)_, C&F éditions, 2012
- Armand et Michèle Mattelart, _Histoire des théories de la communication_, 3ᵉ édition, La découverte, 2004 (voir la [4ème édition](https://www.editionsladecouverte.fr/histoire_des_theories_de_la_communication-9782348040672) publiée en 2018)
- C. d. Gournay, « [Télécommunications et philosophie des réseaux. La postérité paradoxale de Saint-Simon (Pierre Musso) \[compte-rendu\]](https://www.persee.fr/doc/reso_0751-7971_1997_num_15_82_3080) », Réseaux. Communication - Technologie - Société 15, p301-304, 1997
- Pierre Musso, _[Critique des réseaux](https://www.cairn.info/critique-des-reseaux--9782130501374.htm)_, PUF, 2003
- Paul N. Edwards, _[Un monde clos](https://editions-b2.com/les-livres/7-un-monde-clos.html)_, éditions B2, 2013 (texte original [publié aux MIT press](https://mitpress.mit.edu/books/closed-world) en 1996)

## Script de la chronique

Jingle\
🎶 Père Noël, raconte nous des histoires 🎶\
Bonjour les enfants...\
Bonjour Père Noël...\
Aujourd'hui, je vais vous raconter une belle histoire.\
Allez, c'est parti...

« Il était une fois, une société sans internet et sans Web.\
Dans ce monde, les gens avides de connaissance allaient dans des bibliothèques.\
De lourds ouvrages étaient rangés dans de grands rayons.\
On devait passer de l'un, à l'autre, et de l'un à l'autre, et de l'un, à l'autre...\
C'était fatigants.\
Les gens n'étaient pas contents.\
Qui les libéra de ce dur labeur ?\
✊ Hypertext ! ✊ Hypertext ! ✊ Hypertext !»

Eh ouai, aujourd'hui, j'vais encore vous parler d'hypertext.
La question, forcément, c'est : qui a eu l'idée en premier ?

Là, vous trouverez toujours quelqu'un pour vous répondre : "Bush".\
Alors non, pas le président américain qui a failli se tuer en bouffant des bretzels...\
_...et ouiii, j'ai conscience que cette vanne ne sera comprise que par les 30 ans et plus._

Là je parle de **Va-NII-var** Bush.\
LE mec universellement cité comme l'un des plus grands visionnaires de tous les temps.\
LE mec qui aurait prophétisé l'hypertexte, mais aussi internet, les réseaux sociaux, les smartphones ... tout quoi !

Et tout ça en 1945, en UN article : "As We May Think" ("Comme nous pourrions penser").\
Donc là c'est bon, j'ai fini ma chronique, tout le monde est content, bonjour chez vous.

Je sais-pas si on vous l'a déjà dit, mais généralement, c'est plutôt une bonne idée d'aller lire un article qu'on vous a partagé.\
Ne pas s'arrêter au titre, vérifier les sources, tout ça tout ça quoi.

Bon ben, on va jeter un coup d'œil du coup.

Alors déjà, un peu de contexte.

Va-NII-var bush est un ingénieur.\
En 1927, il créé même un "proto-ordinateurs" mécanique.\
(Une espèce de délire steam punk pesant dans les 100 tonnes.\
Ça fonctionnait comme une horloge, avec des roues crantées et tout le tintouin).

Durant la seconde guerre mondial, il s'occupe surtout d'organiser et diriger la recherche militaire.\
Il est même une des personnalités clé du projet Manhattan.\
Donc basiquement, c'est LE mec à l'origine de la bombe nucléaire.

Alors oui, la recherche durant la der des der, c'était pas que ça hein.\
C'était aussi et surtout l'occasion de faire collaborer plein de domaines différents.\
La cybernétique a d'ailleurs été créée pour aider tout ce beau monde à communiquer.\
C'était les débuts des sciences de la communication, et donc, de l'informatique.

Du coup, notre ami Bush a sans aucun doute bénéficié de ces influences, huuum ?!\
Chapoter tout ce joyeux bordel lui a **forcément** permis de TOUT comprendre, eh ouai.

Alors, voyons voyons cet article...

Bla bla bla...\
Lyrisme...\
Machine de Babbage...\
Lyrisme...\
Vision exaltée des sciences et de l'industrie...\
Bla bla bla...

Ah, Partie 2

« Les progrès de la photographie ne sont certainement pas prêts de s’arrêter.\
Voyons ce que ces découvertes vont **logiquement** voire **inévitablement** impliquer.\
•\
L’appareil photographique du futur se porte sur le front, et a la forme d’une bosse à peine plus grande qu’une noix. »

C'est **cette image** qu'il a décidé de mettre pour illustrer l'article.\
Un dessin, montrant le haut du visage d'un mec, avec une webcam sur le front, attachée par des sangles.\
Un visionnaire j'vous dit !

Bon, du coup, il cause photo pendant un long moment après ça.\
Mais c'est pas du tout anodin.\
Mr Bush a beaucoup travaillé sur les microfilms.\
Microfilms qui sont toujours beaucoup utilisés dans les années 40, pour compresser l'information.\
Basiquement, tu prends une photo d'un document (imagine une feuille A4), et tu la stoque sur un espace de quelques millimètres.

"Le microfilm de l’encyclopédie Britannica pourrait être envoyé par la poste pour un centime."

Nickel, on a donc la technique de stockage du turfu.

Bon, pour être honnête, l'auteur évoque également les cartes perforées, donc le binaire, dans le 3ème partie de l'article.

« Les machines arithmétique du futur pourront être de nature électrique et s’exécuter 100 fois plus vite qu’actuellement, si ce n’est plus. »\
(ou shouia oui...)

« De telles machines auront un appétit énorme.\
L’une d’entre elles recevra les instructions et les données d’une pièce remplie de demoiselles armées de claviers perforateurs, et cette machine délivrera chaque minute des feuilles de résultats. »

Aaaah, le bon vieux sexisme des années 40, miam miam.\
Parce que oui, aux débuts, l'essentiel des informaticiens étaient des informaticiennes.\
Eh ouai.\
Coder, ça se faisait sur une sorte de machine à écrire.

> Voix de gros lourd

Donc, eh - oh, c'est un boulot de secrétaire ça, roh - ah.\
Du coup c'est facile, hein, rohlala.

Et que je te justifie ça à base de plein de clichés genrés du style :\
"c'est du langage"\
"c'est de l'émotionnel"\
etc...

Après, l'informatique est devenue centrale.\
Ça a commencé à être mieux considéré.\
Et du coup, à être bien payé.\
Et c'est devenu un "métier d'homme".\
Avec des justifications a la mort moi le jonc, comme :\
"c'est scientifique"\
"c'est des maths"\
Bref, plein de représentations débiles qui impliquent donc, a priori, qu'on tape sur un clavier avec sa bite.\
Vous remarquerez que tout ça est toujours d'actualité, oooh joie.

BBBBRRRRef !

L'article présente ensuite le Memex.\
Une machine imaginaire, permettant de consulter des microfilms connectés entre eux.\
C'est généralement ce passage qui sera le plus cité et le plus retenu.\
Car il s'agit bien de la première évocation médiatisée d'un "proto-hypertexte".

Sauf que ...

Le Memex est tout aussi délirant dans sa présentation que la webcam sur le front.\
Va-NI-var bush a totalement surestimé l'importance des microfilms.\
Toutes ses prospectives tournent autour de cette idée.\
Il est obsédé par les sens qui permettent de transmettre l'information.\
En particulier la vue et l'ouïe.\
Du coup, il en oublie d'étudier ce qui constitue réellement l'information elle-même.

Vous me direz, il est facile de tenir de tels propos 80 ans plus tard.\
Eh vous aurez entièrement raison !

"As we may think" est sans doute unique en son genre.\
Plusieurs auteurs avaient déjà "dégrossi" le sujet bien avant Bush.\
Mais son évocation des "liens entre document" est élégante, et comprends quelques concepts novateurs.

Mais...
je suis personnellement persuadé que de nombreuses personnes, qui travaillaient effectivement sur les premiers ordinateurs, auraient pu indiquer à Bush son erreur, ou du moins, de modérer son propos.\
Ces personnes ne sont pourtant jamais nommées dans l'article.\
Alors même que c'est leurs travaux qui en inspirent les parties les plus justes et intéressantes.

Finalement, c'est bien l'homme en position de pouvoir, occupant l'espace sans modération, qui marque les esprits et rentre dans les livres d'histoire.

Comme quoi, la situation date pas d'hier.

...

Quoi qu'il en soit, l'article est super intéressant.\
Franchement, allez le lire, vous serez pas déçus.

Je partagerai les liens sur Twitter juste après ce live, et un petit peu plus tard sur fullweb.dev en même temps que des compléments pour tout le monde, y compris si vous nous écouter en podcast.\
Si vous être sur Youtube, les liens devraient se trouver ci-dessous.

Merci à tous, à vous, le studios.
(j'ai toujours rêvé de dire ça)
